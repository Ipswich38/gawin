import { validationService } from './validationService';
import { systemGuardianService } from './systemGuardianService';

export interface DeepSeekMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface DeepSeekResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: {
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }[];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface DeepSeekConfig {
  model: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
}

class DeepSeekService {
  private static instance: DeepSeekService;
  private apiKey: string;
  private baseURL: string = 'https://api.deepseek.com/v1';

  private constructor() {
    // For now, we'll use a mock implementation since we're removing third-party dependencies
    this.apiKey = process.env.DEEPSEEK_API_KEY || '';
    
    if (!this.apiKey) {
      console.warn('‚ö†Ô∏è DeepSeek API key not found. Using mock responses.');
    }
  }

  static getInstance(): DeepSeekService {
    if (!DeepSeekService.instance) {
      DeepSeekService.instance = new DeepSeekService();
    }
    return DeepSeekService.instance;
  }

  /**
   * Check if the service is properly configured
   */
  isConfigured(): boolean {
    return this.apiKey !== '';
  }

  /**
   * Create a chat completion
   */
  async createChatCompletion(
    messages: DeepSeekMessage[],
    config: DeepSeekConfig = { model: 'deepseek-chat' }
  ): Promise<DeepSeekResponse> {
    try {
      // Validate messages first
      const validatedMessages = this.validateMessages(messages);

      if (!this.isConfigured()) {
        // Return a mock response when not configured
        return this.createMockResponse(validatedMessages, config);
      }

      // Prepare request payload
      const payload = {
        model: config.model || 'deepseek-chat',
        messages: validatedMessages,
        temperature: config.temperature || 0.7,
        max_tokens: config.max_tokens || 2048,
        stream: false
      };

      // Make API request
      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        throw new Error(`DeepSeek API error: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data as DeepSeekResponse;

    } catch (error) {
      console.error('DeepSeek service error:', error);
      
      // Fallback to mock response on error
      return this.createMockResponse(messages, config);
    }
  }

  /**
   * Validate messages for content safety
   */
  private validateMessages(messages: DeepSeekMessage[]): DeepSeekMessage[] {
    return messages.filter(message => {
      try {
        const validation = validationService.validateTextInput(message.content);
        return validation.isValid;
      } catch (error) {
        console.warn('Message validation failed:', error);
        return false;
      }
    });
  }

  /**
   * Create a mock response when API is not available
   */
  private createMockResponse(messages: DeepSeekMessage[], config: DeepSeekConfig): DeepSeekResponse {
    const lastUserMessage = messages.filter(m => m.role === 'user').pop();
    const userInput = lastUserMessage?.content || '';
    
    // Generate contextual mock responses
    let mockContent = this.generateMockResponse(userInput);

    return {
      id: `mock-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: config.model || 'deepseek-chat',
      choices: [{
        index: 0,
        message: {
          role: 'assistant',
          content: mockContent
        },
        finish_reason: 'stop'
      }],
      usage: {
        prompt_tokens: this.estimateTokens(messages.map(m => m.content).join(' ')),
        completion_tokens: this.estimateTokens(mockContent),
        total_tokens: this.estimateTokens(messages.map(m => m.content).join(' ') + mockContent)
      }
    };
  }

  /**
   * Generate contextual mock responses
   */
  private generateMockResponse(input: string): string {
    const lowerInput = input.toLowerCase();
    
    // Math and science
    if (/math|equation|solve|calculate|algebra|geometry|calculus/.test(lowerInput)) {
      return "I'd be happy to help with math problems! While I can provide general mathematical guidance, for advanced calculations and step-by-step solutions, our specialized STEM models (DeepSeek-R1-Distill-Qwen-32B) provide more detailed assistance. What specific math topic would you like help with?";
    }
    
    // Coding
    if (/code|program|function|javascript|python|html|css|react/.test(lowerInput)) {
      return "I can definitely help with coding! I can provide general programming guidance, but for detailed code examples, debugging, and best practices, our coding specialist (DeepSeek-Coder-V2) offers comprehensive development assistance. What programming challenge can I help you with?";
    }
    
    // Writing
    if (/write|essay|story|letter|creative/.test(lowerInput)) {
      return "I'd love to help with your writing! I can offer general writing advice and tips. For detailed feedback, grammar checking, and creative writing assistance, our writing specialist (Qwen2.5-72B) provides comprehensive support. What type of writing are you working on?";
    }
    
    // Greetings
    if (/hello|hi|hey|good morning|good afternoon/.test(lowerInput)) {
      return "Hello! I'm Gawin AI, your intelligent learning companion. I'm here to help with your studies, answer questions, and assist with learning. I have access to specialized AI models for different subjects. What would you like to learn about today?";
    }
    
    // Default response
    return `I understand you're asking about "${input}". I'm ready to help! I have access to different specialized AI models depending on your needs:

üß† **STEM & Analysis**: Advanced mathematical reasoning
üíª **Coding**: Programming help and debugging  
üìù **Writing**: Essay help and creative writing
üé® **Images**: AI art generation with Kandinsky 3.0

What specific topic would you like to explore?`;
  }

  /**
   * Estimate token count (rough approximation)
   */
  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4);
  }

  /**
   * Get available models (mock for now)
   */
  getAvailableModels() {
    return {
      'deepseek-chat': {
        description: 'General purpose chat model',
        context_length: 4096
      },
      'deepseek-coder': {
        description: 'Code-focused model',
        context_length: 8192
      }
    };
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<{ status: 'healthy' | 'degraded' | 'offline'; message: string }> {
    try {
      if (!this.isConfigured()) {
        return { status: 'degraded', message: 'Running in demo mode - API key not configured' };
      }

      // Test API connection
      const testResponse = await this.createChatCompletion([
        { role: 'user', content: 'Hello' }
      ]);

      if (testResponse.choices && testResponse.choices.length > 0) {
        return { status: 'healthy', message: 'DeepSeek API operational' };
      } else {
        return { status: 'degraded', message: 'API responding but with issues' };
      }
    } catch (error) {
      return { status: 'offline', message: 'API unavailable - using fallback responses' };
    }
  }
}

// Export singleton instance
export const deepseekService = DeepSeekService.getInstance();
export default deepseekService;